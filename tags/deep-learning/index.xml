<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Deep-Learning :: Tag :: Black_JJW&#39;s Blog</title>
    <link>https://blackjjw.github.io/tags/deep-learning/index.html</link>
    <description></description>
    <generator>Hugo</generator>
    <language>en-us</language>
    <atom:link href="https://blackjjw.github.io/tags/deep-learning/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>1. Single-Layer Perceptron</title>
      <link>https://blackjjw.github.io/learning_notes/dl/slp/index.html</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://blackjjw.github.io/learning_notes/dl/slp/index.html</guid>
      <description>Single-Layer Perceptron (SLP) is one of the simplest neural network architectures. It processes an input vector through a linear combination of weights and an activation function to generate an output.&#xA;To produce an output vector, the SLP uses one perceptron for each scalar element in the output.&#xA;In this image, $P_{1},\ P_{2},\ P_{3}$ are perceptrons that produce an output vector of size 3.</description>
    </item>
    <item>
      <title>2. Tensor Operation &amp; Minibatch</title>
      <link>https://blackjjw.github.io/learning_notes/dl/tensoropsminibatch/index.html</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://blackjjw.github.io/learning_notes/dl/tensoropsminibatch/index.html</guid>
      <description>In the field of deep learning, the tensor is like a multi-dimension numerical array.&#xA;0-dim: scalar 1-dim: vector 2-dim: matrix n-dim: general tensor Tensors are fundamental because they allow data to be represented and processed efficiently in any number of dimensions. In Python, tensors are often represented with NumPy array or framework-specific tensor objects such as those in PyTorch or TensorFlow.&#xA;Using tensors is simpler and faster than using explicit loops.</description>
    </item>
    <item>
      <title>3. Regression Analysis &amp; MSE Loss function</title>
      <link>https://blackjjw.github.io/learning_notes/dl/regressionandmse/index.html</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://blackjjw.github.io/learning_notes/dl/regressionandmse/index.html</guid>
      <description>In regression analysis, a deep learning neural network can produce more accurate predictions (or estimates) when it is trained on appropriate input data, its architecture is well-suited to the problem, and the training process is properly carried out.&#xA;In deep learning, quantitative metrics are needed to evaluate the accuracy of the modelâ€™s predictions.&#xA;When evaluating regression predictions, the Mean Squared Error (MSE) is commonly used as the loss function.&#xA;The Mean Squared Error is defined as:</description>
    </item>
  </channel>
</rss>