<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Minibatch :: Tag :: Black_JJW&#39;s Blog</title>
    <link>https://blackjjw.github.io/tags/minibatch/index.html</link>
    <description></description>
    <generator>Hugo</generator>
    <language>en-us</language>
    <atom:link href="https://blackjjw.github.io/tags/minibatch/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>2. Tensor Operation &amp; Minibatch</title>
      <link>https://blackjjw.github.io/learning_notes/dl/tensoropsminibatch/index.html</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://blackjjw.github.io/learning_notes/dl/tensoropsminibatch/index.html</guid>
      <description>In the field of deep learning, the tensor is like a multi-dimension numerical array.&#xA;0-dim: scalar 1-dim: vector 2-dim: matrix n-dim: general tensor Tensors are fundamental because they allow data to be represented and processed efficiently in any number of dimensions. In Python, tensors are often represented with NumPy array or framework-specific tensor objects such as those in PyTorch or TensorFlow.&#xA;Using tensors is simpler and faster than using explicit loops.</description>
    </item>
  </channel>
</rss>