<!DOCTYPE html>
<html class="no-js" lang="en">
<head>
	<meta charset="UTF-8">
	<meta name="viewport" content="width=device-width, initial-scale=1">
	<meta http-equiv="X-UA-Compatible" content="IE=edge">
	<title>[DL][Book][혼공 머신러닝&#43;딥러닝]ch8-3 합성곱 신경망의 시각화 - Black_JJW&#39;s Blog</title>
	<script>(function(d,e){d[e]=d[e].replace("no-js","js");})(document.documentElement,"className");</script>
	<meta name="description" content="">
		<meta property="og:title" content="[DL][Book][혼공 머신러닝&#43;딥러닝]ch8-3 합성곱 신경망의 시각화" />
<meta property="og:description" content="" />
<meta property="og:type" content="article" />
<meta property="og:url" content="/post/dl/book/chapter8_3/" /><meta property="article:section" content="post" />
<meta property="article:published_time" content="2022-05-03T17:30:45+09:00" />
<meta property="article:modified_time" content="2022-05-03T17:30:45+09:00" />


	<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
	<link rel="dns-prefetch" href="//fonts.googleapis.com">
	<link rel="dns-prefetch" href="//fonts.gstatic.com">
	<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Open+Sans:400,400i,700">

	<link rel="stylesheet" href="/css/style.css">
	

	<link rel="shortcut icon" href="/favicon.ico">
		
</head>
<body class="body">
	<div class="container container--outer">
		<header class="header">
	<div class="container header__container">
		
	<div class="logo">
		<a class="logo__link" href="/" title="Black_JJW&#39;s Blog" rel="home">
			<div class="logo__item logo__text">
					<div class="logo__title">Black_JJW&#39;s Blog</div>
					<div class="logo__tagline">Create, Read, Update, Delete</div>
				</div>
		</a>
	</div>
		
<nav class="menu">
	<button class="menu__btn" aria-haspopup="true" aria-expanded="false" tabindex="0">
		<span class="menu__btn-title" tabindex="-1">Menu</span>
	</button>
	<ul class="menu__list">
		<li class="menu__item">
			<a class="menu__link" href="/">
				
				<span class="menu__text">Home</span>
				
			</a>
		</li>
		<li class="menu__item">
			<a class="menu__link" href="/categories/python/">
				
				<span class="menu__text">Python</span>
				
			</a>
		</li>
		<li class="menu__item">
			<a class="menu__link" href="/categories/setting/">
				
				<span class="menu__text">Setting</span>
				
			</a>
		</li>
		<li class="menu__item">
			<a class="menu__link" href="/categories/ml/">
				
				<span class="menu__text">ML</span>
				
			</a>
		</li>
		<li class="menu__item">
			<a class="menu__link" href="/categories/dl/">
				
				<span class="menu__text">DL</span>
				
			</a>
		</li>
		<li class="menu__item">
			<a class="menu__link" href="/categories/kaggle/">
				
				<span class="menu__text">Kaggle</span>
				
			</a>
		</li>
		<li class="menu__item">
			<a class="menu__link" href="/categories/projects/">
				
				<span class="menu__text">Projects</span>
				
			</a>
		</li>
		<li class="menu__item">
			<a class="menu__link" href="/categories/statistics/">
				
				<span class="menu__text">statistics</span>
				
			</a>
		</li>
		<li class="menu__item">
			<a class="menu__link" href="/categories/sql/">
				
				<span class="menu__text">sql</span>
				
			</a>
		</li>
		<li class="menu__item">
			<a class="menu__link" href="/categories/javascript/">
				
				<span class="menu__text">JavaScript</span>
				
			</a>
		</li>
		<li class="menu__item">
			<a class="menu__link" href="/about/">
				
				<span class="menu__text">About</span>
				
			</a>
		</li>
	</ul>
</nav>

	</div>
</header>
		<div class="wrapper flex">
			<div class="primary">
			
<main class="main" role="main">
	<article class="post">
		<header class="post__header">
			<h1 class="post__title">[DL][Book][혼공 머신러닝&#43;딥러닝]ch8-3 합성곱 신경망의 시각화</h1>
			<div class="post__meta meta">
<div class="meta__item-datetime meta__item">
	<svg class="meta__icon icon icon-time" width="16" height="14" viewBox="0 0 30 28"><path d="M15 0C7 0 1 6 1 14s6 14 14 14 14-6 14-14S23 0 15 0zm0 25C9 25 4 20 4 14S9 3 15 3s11 5 11 11-5 11-11 11zm1-18h-2v8.4l6.8 4.4L22 18l-6-3.8V7z"/></svg><time class="meta__text" datetime="2022-05-03T17:30:45&#43;09:00">May 03, 2022</time></div><div class="meta__item-categories meta__item"><svg class="meta__icon icon icon-category" width="16" height="16" viewBox="0 0 16 16"><path d="m7 2l1 2h8v11h-16v-13z"/></svg><span class="meta__text"><a class="meta__link" href="/categories/dl/" rel="category">DL</a>
	</span>
</div></div>
		</header>
		<div class="content post__content clearfix">
			<h2 id="가중치-시각화">가중치 시각화</h2>
<ul>
<li>합성곱 층은 여러 개의 필터를 사용해 이미지에서 특징을 학습</li>
<li>각 필터는 커널이라는 가중치와 절편을 가지고 있음</li>
<li>일반적으로 절편은 시각적으로 의미가 없음</li>
<li>가중치는 입력 이미지의 2차원 영역에 적용되어 어떤 특징을 크게 두드러지게 표현하는 역할</li>
</ul>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#f92672">from</span> tensorflow <span style="color:#f92672">import</span> keras
</span></span><span style="display:flex;"><span>model <span style="color:#f92672">=</span> keras<span style="color:#f92672">.</span>models<span style="color:#f92672">.</span>load_model(<span style="color:#e6db74">&#39;best-cnn-model.h5&#39;</span>)
</span></span></code></pre></div><div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span>model<span style="color:#f92672">.</span>layers
</span></span></code></pre></div><pre><code>[&lt;keras.layers.convolutional.Conv2D at 0x7fc398c6fed0&gt;,
 &lt;keras.layers.pooling.MaxPooling2D at 0x7fc390653c90&gt;,
 &lt;keras.layers.convolutional.Conv2D at 0x7fc390653490&gt;,
 &lt;keras.layers.pooling.MaxPooling2D at 0x7fc390653850&gt;,
 &lt;keras.layers.core.flatten.Flatten at 0x7fc390591b10&gt;,
 &lt;keras.layers.core.dense.Dense at 0x7fc390595c90&gt;,
 &lt;keras.layers.core.dropout.Dropout at 0x7fc3905a12d0&gt;,
 &lt;keras.layers.core.dense.Dense at 0x7fc390589490&gt;]
</code></pre>
<ul>
<li>
<p>model.layers 리스트에 이전 절에서 추가했던 Conv2D, MaxPooling2D 층이 번갈아 2번 연속 등장</p>
</li>
<li>
<p>그 다음 Flatten 층과 Dense 층, Dropout 층이 차례대로 등장</p>
</li>
<li>
<p>마지막에 Dense 출력층이 놓여있음</p>
</li>
<li>
<p>첫 번째 합성곱 층의 가중치</p>
<ul>
<li>층의 가중치와 절편은 층의 weights 속성에 저장</li>
</ul>
</li>
</ul>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span>conv <span style="color:#f92672">=</span> model<span style="color:#f92672">.</span>layers[<span style="color:#ae81ff">0</span>]
</span></span><span style="display:flex;"><span>print(conv<span style="color:#f92672">.</span>weights[<span style="color:#ae81ff">0</span>]<span style="color:#f92672">.</span>shape, conv<span style="color:#f92672">.</span>weights[<span style="color:#ae81ff">1</span>]<span style="color:#f92672">.</span>shape)
</span></span></code></pre></div><pre><code>(3, 3, 1, 32) (32,)
</code></pre>
<ul>
<li>
<p>합성곱 층에 전달되는 입력의 깊이가 1이므로 실제 커널의 크기는 (3, 3, 1)</p>
</li>
<li>
<p>필터 개수가 32개이므로 weights의 첫 번째 원소인 가중치의 크기는 (3, 3, 1, 32)가 됨</p>
</li>
<li>
<p>weights의 두 번째 원소는 절편의 개수를 나타냄</p>
</li>
<li>
<p>필터마다 1개의 절편이 있으므로 (32,) 크기가 됨</p>
</li>
<li>
<p>weights 속성은 텐서플로의 다차원 배열인 Tensor 클래스의 객체</p>
</li>
<li>
<p>여기서는 넘파이 배열로 변환</p>
</li>
</ul>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span>conv_weights <span style="color:#f92672">=</span> conv<span style="color:#f92672">.</span>weights[<span style="color:#ae81ff">0</span>]<span style="color:#f92672">.</span>numpy()
</span></span><span style="display:flex;"><span>print(conv_weights<span style="color:#f92672">.</span>mean(), conv_weights<span style="color:#f92672">.</span>std())
</span></span></code></pre></div><pre><code>-0.028283767 0.24100564
</code></pre>
<ul>
<li>이 가중치의 평균값은 0에 가깝고, 표준편차는 0.24 정도</li>
</ul>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#f92672">import</span> matplotlib.pyplot <span style="color:#66d9ef">as</span> plt
</span></span><span style="display:flex;"><span>plt<span style="color:#f92672">.</span>hist(conv_weights<span style="color:#f92672">.</span>reshape(<span style="color:#f92672">-</span><span style="color:#ae81ff">1</span>, <span style="color:#ae81ff">1</span>))
</span></span><span style="display:flex;"><span>plt<span style="color:#f92672">.</span>xlabel(<span style="color:#e6db74">&#39;weight&#39;</span>)
</span></span><span style="display:flex;"><span>plt<span style="color:#f92672">.</span>ylabel(<span style="color:#e6db74">&#39;count&#39;</span>)
</span></span><span style="display:flex;"><span>plt<span style="color:#f92672">.</span>show()
</span></span></code></pre></div><p><img src="/images/self_study_ml_dl_images/chapter8_3/output_12_0.png" alt="png"></p>
<ul>
<li>
<p>맷플롯립의 hist() 함수에 히스토그램을 그리기 위해 1차원 배열로 전달</p>
</li>
<li>
<p>reshape() 메서드로 conv_weights 배열을 1개의 열이 있는 배열로 변환</p>
</li>
<li>
<p>이번에는 32개의 커널을 16개씩 두 줄에 출력</p>
</li>
</ul>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span>fig, axs <span style="color:#f92672">=</span> plt<span style="color:#f92672">.</span>subplots(<span style="color:#ae81ff">2</span>, <span style="color:#ae81ff">16</span>, figsize<span style="color:#f92672">=</span>(<span style="color:#ae81ff">15</span>, <span style="color:#ae81ff">2</span>))
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">for</span> i <span style="color:#f92672">in</span> range(<span style="color:#ae81ff">2</span>):
</span></span><span style="display:flex;"><span>  <span style="color:#66d9ef">for</span> j <span style="color:#f92672">in</span> range(<span style="color:#ae81ff">16</span>):
</span></span><span style="display:flex;"><span>    axs[i, j]<span style="color:#f92672">.</span>imshow(conv_weights[:,:,<span style="color:#ae81ff">0</span>,i<span style="color:#f92672">*</span><span style="color:#ae81ff">16</span> <span style="color:#f92672">+</span> j], vmin<span style="color:#f92672">=-</span><span style="color:#ae81ff">0.5</span>, vmax<span style="color:#f92672">=</span><span style="color:#ae81ff">0.5</span>)
</span></span><span style="display:flex;"><span>    axs[i, j]<span style="color:#f92672">.</span>axis(<span style="color:#e6db74">&#39;off&#39;</span>)
</span></span><span style="display:flex;"><span>plt<span style="color:#f92672">.</span>show()
</span></span></code></pre></div><p><img src="/images/self_study_ml_dl_images/chapter8_3/output_15_0.png" alt="png"></p>
<ul>
<li>
<p>conv_weights에 32개의 가중치를 저장</p>
</li>
<li>
<p>이 배열의 마지막 차원을 순회하면서 0부터 i*16 + j번째까지의 가중치 값을 차례대로 출력</p>
</li>
<li>
<p>i는 행 인덱스, j는 열 인덱스</p>
</li>
<li>
<p>conv_weights[:,:,0,0]에서 conv_weights[:,:,0,31]까지 출력</p>
</li>
<li>
<p>imshow() 함수는 배열에 있는 최댓값과 최솟값을 사용해 픽셀의 강도를 표현</p>
<ul>
<li>그 배열의 최댓값이면 가장 밝은 노란색을 그림</li>
</ul>
</li>
<li>
<p>이번에는 훈련하지 않는 빈 합성곱 신경망을 생성</p>
</li>
<li>
<p>이 합성곱 층의 가중치가 위에서 본 훈련한 가중치와 어떻게 다른지 그림으로 비교</p>
</li>
<li>
<p>먼저 Sequential 클래스로 모델을 만들고 Conv2D 층을 하나 추가</p>
</li>
</ul>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span>no_training_model <span style="color:#f92672">=</span> keras<span style="color:#f92672">.</span>Sequential()
</span></span><span style="display:flex;"><span>no_training_model<span style="color:#f92672">.</span>add(keras<span style="color:#f92672">.</span>layers<span style="color:#f92672">.</span>Conv2D(<span style="color:#ae81ff">32</span>, kernel_size<span style="color:#f92672">=</span><span style="color:#ae81ff">3</span>, activation<span style="color:#f92672">=</span><span style="color:#e6db74">&#39;relu&#39;</span>,
</span></span><span style="display:flex;"><span>                                          padding<span style="color:#f92672">=</span><span style="color:#e6db74">&#39;same&#39;</span>, input_shape<span style="color:#f92672">=</span>(<span style="color:#ae81ff">28</span>, <span style="color:#ae81ff">28</span>, <span style="color:#ae81ff">1</span>)))
</span></span></code></pre></div><ul>
<li>이 모델의 첫 번째 층 (Conv2D 층)의 가중치를 no_training_conv 변수에 저장</li>
</ul>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span>no_training_conv <span style="color:#f92672">=</span> no_training_model<span style="color:#f92672">.</span>layers[<span style="color:#ae81ff">0</span>]
</span></span><span style="display:flex;"><span>print(no_training_conv<span style="color:#f92672">.</span>weights[<span style="color:#ae81ff">0</span>]<span style="color:#f92672">.</span>shape)
</span></span></code></pre></div><pre><code>(3, 3, 1, 32)
</code></pre>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span>no_training_weights <span style="color:#f92672">=</span> no_training_conv<span style="color:#f92672">.</span>weights[<span style="color:#ae81ff">0</span>]<span style="color:#f92672">.</span>numpy()
</span></span><span style="display:flex;"><span>print(no_training_weights<span style="color:#f92672">.</span>mean(), no_training_weights<span style="color:#f92672">.</span>std())
</span></span></code></pre></div><pre><code>-0.003443989 0.081783295
</code></pre>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span>plt<span style="color:#f92672">.</span>hist(no_training_weights<span style="color:#f92672">.</span>reshape(<span style="color:#f92672">-</span><span style="color:#ae81ff">1</span>, <span style="color:#ae81ff">1</span>))
</span></span><span style="display:flex;"><span>plt<span style="color:#f92672">.</span>xlabel(<span style="color:#e6db74">&#39;weight&#39;</span>)
</span></span><span style="display:flex;"><span>plt<span style="color:#f92672">.</span>ylabel(<span style="color:#e6db74">&#39;count&#39;</span>)
</span></span><span style="display:flex;"><span>plt<span style="color:#f92672">.</span>show()
</span></span></code></pre></div><p><img src="/images/self_study_ml_dl_images/chapter8_3/output_23_0.png" alt="png"></p>
<ul>
<li>그래프가 이전과 달라진 이유는 텐서플로가 신경망의 가중치를 처음 초기화할 때 균등 분포에서 랜덤하게 값을 선택하기 때문</li>
</ul>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span>fig, axs <span style="color:#f92672">=</span> plt<span style="color:#f92672">.</span>subplots(<span style="color:#ae81ff">2</span>, <span style="color:#ae81ff">16</span>, figsize<span style="color:#f92672">=</span>(<span style="color:#ae81ff">15</span>, <span style="color:#ae81ff">2</span>))
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">for</span> i <span style="color:#f92672">in</span> range(<span style="color:#ae81ff">2</span>):
</span></span><span style="display:flex;"><span>  <span style="color:#66d9ef">for</span> j <span style="color:#f92672">in</span> range(<span style="color:#ae81ff">16</span>):
</span></span><span style="display:flex;"><span>    axs[i, j]<span style="color:#f92672">.</span>imshow(no_training_weights[:,:,<span style="color:#ae81ff">0</span>,i<span style="color:#f92672">*</span><span style="color:#ae81ff">16</span> <span style="color:#f92672">+</span> j], vmin<span style="color:#f92672">=-</span><span style="color:#ae81ff">0.5</span>, vmax<span style="color:#f92672">=</span><span style="color:#ae81ff">0.5</span>)
</span></span><span style="display:flex;"><span>    axs[i, j]<span style="color:#f92672">.</span>axis(<span style="color:#e6db74">&#39;off&#39;</span>)
</span></span><span style="display:flex;"><span>plt<span style="color:#f92672">.</span>show()
</span></span></code></pre></div><p><img src="/images/self_study_ml_dl_images/chapter8_3/output_25_0.png" alt="png"></p>
<ul>
<li>가중치가 밋밋하게 초기화됨</li>
</ul>
<h2 id="함수형-api">함수형 API</h2>
<ul>
<li>함수형 API(fucntional API)는 케라스의 Model 클래스를 사용하여 모델을 만듬</li>
<li>Dense 층 2개로 이루어진 완전 연결 신경망을 함수형 API로 구현</li>
</ul>
<pre tabindex="0"><code>dense1 = keras.layers.Dense(100, activation = &#39;sigmoid&#39;)
dense2 = keras.layers.Dense(10, activation = &#39;softmax&#39;)
</code></pre><ul>
<li>이 객체를 Sequential 클래스 객체의 add() 메서드에 전달 가능</li>
<li>하지만 다음과 같이 함수처럼 호출 가능</li>
</ul>
<pre tabindex="0"><code>hidden = dense1(inputs)
</code></pre><ul>
<li>두 번째 층 호출</li>
</ul>
<pre tabindex="0"><code>outputs = dense2(hidden)
</code></pre><ul>
<li>inputs와 outputs을 Model 클래스로 연결</li>
</ul>
<pre tabindex="0"><code>model = keras.Model(inputs, outputs)
</code></pre><ul>
<li>
<p>입력에서 출력까지 층을 호출한 결과를 계속 이어주고 Model 클래스에 입력과 최종 출력을 지정</p>
</li>
<li>
<p>Sequential 클래스는 InputLayer 클래스를 자동으로 추가하고 호출해 주지만 Model 클래스에서는 수동으로 만드러서 호출해야함</p>
<ul>
<li>inputs는 InputLayer 클래스의 출력값</li>
</ul>
</li>
<li>
<p>케라스는 InputLayer 클래스 객체를 쉽게 다룰수 있도록 Input() 함수를 별도로 제공</p>
</li>
<li>
<p>입력의 크기를 지정하는 shape 매개변수와 함께 이 함수를 호출하면 InputLayer 클래스 객체를 만들어 출력을 반환</p>
</li>
</ul>
<pre tabindex="0"><code>inputs = keras.Input(shape=(784,))
</code></pre><ul>
<li>
<p>model 객체 순서<br>
model 객체 - InputLayer -&gt; Conv2D -&gt; MaxPooling2D -&gt; Conv2D -&gt; MaxPooling2D -&gt; Flatten -&gt; Dense -&gt; Dropout -&gt; Dense</p>
</li>
<li>
<p>필요한 것은 첫 번째 Conv2D의 출력</p>
</li>
<li>
<p>model 객체의 입려과 Conv2D의 출력을 알 수 있다면 이 둘을 연결하여 새로운 모델을 얻을 수 있음</p>
</li>
<li>
<p>model 객체의 predict() 메서드를 호출하면 입력부터 마지막 층까지 모든 계산을 수행한 후 최종 출력을 반환</p>
</li>
<li>
<p>첫 번째 Conv2D의 출력 : model.layers[0].output</p>
</li>
<li>
<p>model 객체의 입력 : model.input</p>
</li>
</ul>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span>print(model<span style="color:#f92672">.</span>input)
</span></span></code></pre></div><pre><code>KerasTensor(type_spec=TensorSpec(shape=(None, 28, 28, 1), dtype=tf.float32, name='conv2d_input'), name='conv2d_input', description=&quot;created by layer 'conv2d_input'&quot;)
</code></pre>
<ul>
<li>model.input 과 model.layers[0].output 을 연결하는 새로운 conv_acti 모델 생성 가능</li>
</ul>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span>conv_acti <span style="color:#f92672">=</span> keras<span style="color:#f92672">.</span>Model(model<span style="color:#f92672">.</span>input, model<span style="color:#f92672">.</span>layers[<span style="color:#ae81ff">0</span>]<span style="color:#f92672">.</span>output)
</span></span></code></pre></div><ul>
<li>model 객체의 predict() 메서드를 호출하면 최종 출력층의 확률을 반환</li>
<li>conv_acti의 predict() 메서드를 호출하면 첫 번째 Conv2D의 출력을 반환</li>
</ul>
<h2 id="특성-맵-시각화">특성 맵 시각화</h2>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span>(train_input, train_target), (test_input, test_target) <span style="color:#f92672">=</span> keras<span style="color:#f92672">.</span>datasets<span style="color:#f92672">.</span>fashion_mnist<span style="color:#f92672">.</span>load_data()
</span></span><span style="display:flex;"><span>plt<span style="color:#f92672">.</span>imshow(train_input[<span style="color:#ae81ff">0</span>], cmap<span style="color:#f92672">=</span><span style="color:#e6db74">&#39;gray_r&#39;</span>)
</span></span><span style="display:flex;"><span>plt<span style="color:#f92672">.</span>show()
</span></span></code></pre></div><pre><code>Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-labels-idx1-ubyte.gz
32768/29515 [=================================] - 0s 0us/step
40960/29515 [=========================================] - 0s 0us/step
Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-images-idx3-ubyte.gz
26427392/26421880 [==============================] - 1s 0us/step
26435584/26421880 [==============================] - 1s 0us/step
Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-labels-idx1-ubyte.gz
16384/5148 [===============================================================================================] - 0s 0us/step
Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-images-idx3-ubyte.gz
4423680/4422102 [==============================] - 0s 0us/step
4431872/4422102 [==============================] - 0s 0us/step
</code></pre>
<p><img src="/images/self_study_ml_dl_images/chapter8_3/output_41_1.png" alt="png"></p>
<ul>
<li>이 샘플을 conv_acti 모델에 주입하여 Conv2D 층이 만드는 특성 맵을 출력</li>
<li>predict() 메서드는 항상 입력의 첫 번째 차원이 배치 차원일 것을 기대</li>
<li>하나의 샘플을 전달하더라도 꼭 첫 번째 차원을 유지해야 함
<ul>
<li>이를 위해 슬라이싱 연산자를 사용해 첫 번째 샘플을 선택</li>
<li>그 다음 (784,) 크기를 (28, 28, 1) 크기로 변경하고 255로 나눔</li>
</ul>
</li>
</ul>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span>inputs <span style="color:#f92672">=</span> train_input[<span style="color:#ae81ff">0</span>:<span style="color:#ae81ff">1</span>]<span style="color:#f92672">.</span>reshape(<span style="color:#f92672">-</span><span style="color:#ae81ff">1</span>, <span style="color:#ae81ff">28</span>, <span style="color:#ae81ff">28</span>, <span style="color:#ae81ff">1</span>) <span style="color:#f92672">/</span> <span style="color:#ae81ff">255.0</span>
</span></span><span style="display:flex;"><span>feature_maps <span style="color:#f92672">=</span> conv_acti<span style="color:#f92672">.</span>predict(inputs)
</span></span></code></pre></div><div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span>print(feature_maps<span style="color:#f92672">.</span>shape)
</span></span></code></pre></div><pre><code>(1, 28, 28, 32)
</code></pre>
<ul>
<li>세임 패딩과 32개의 필터를 사용한 합성곱 층의 출력이므로 (28, 28, 32)</li>
<li>첫 번째 차원은 배치 차원</li>
<li>샘플을 하나 입력했기 때문에 1</li>
</ul>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span>fig, axs <span style="color:#f92672">=</span> plt<span style="color:#f92672">.</span>subplots(<span style="color:#ae81ff">4</span>, <span style="color:#ae81ff">8</span>, figsize<span style="color:#f92672">=</span>(<span style="color:#ae81ff">15</span>, <span style="color:#ae81ff">8</span>))
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">for</span> i <span style="color:#f92672">in</span> range(<span style="color:#ae81ff">4</span>):
</span></span><span style="display:flex;"><span>  <span style="color:#66d9ef">for</span> j <span style="color:#f92672">in</span> range(<span style="color:#ae81ff">8</span>):
</span></span><span style="display:flex;"><span>    axs[i, j]<span style="color:#f92672">.</span>imshow(feature_maps[<span style="color:#ae81ff">0</span>,:,:,i<span style="color:#f92672">*</span><span style="color:#ae81ff">8</span> <span style="color:#f92672">+</span> j])
</span></span><span style="display:flex;"><span>    axs[i, j]<span style="color:#f92672">.</span>axis(<span style="color:#e6db74">&#39;off&#39;</span>)
</span></span><span style="display:flex;"><span>plt<span style="color:#f92672">.</span>show()
</span></span></code></pre></div><p><img src="/images/self_study_ml_dl_images/chapter8_3/output_46_0.png" alt="png"></p>
<ul>
<li>
<p>이 특성 맵은 32개의 필터로 인해 입력 이미지에서 강하게 활성화된 부분을 보여줌</p>
</li>
<li>
<p>두 번째 합성곱 층이 만든 특성 맵도 같은 방식으로 확인 가능</p>
</li>
<li>
<p>먼저 model 객체의 입력과 두 번째 합성곱 층인 model.layers[2]의 출력을 연결한 conv2_acti 모델을 생성</p>
</li>
</ul>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span>conv2_acti <span style="color:#f92672">=</span> keras<span style="color:#f92672">.</span>Model(model<span style="color:#f92672">.</span>input, model<span style="color:#f92672">.</span>layers[<span style="color:#ae81ff">2</span>]<span style="color:#f92672">.</span>output)
</span></span></code></pre></div><ul>
<li>첫 번째 샘플을 conv2_acti 모델의 predict()메서드에 전달</li>
</ul>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span>inputs <span style="color:#f92672">=</span> train_input[<span style="color:#ae81ff">0</span>:<span style="color:#ae81ff">1</span>]<span style="color:#f92672">.</span>reshape(<span style="color:#f92672">-</span><span style="color:#ae81ff">1</span>, <span style="color:#ae81ff">28</span>, <span style="color:#ae81ff">28</span>, <span style="color:#ae81ff">1</span>) <span style="color:#f92672">/</span> <span style="color:#ae81ff">255.0</span>
</span></span><span style="display:flex;"><span>feature_maps <span style="color:#f92672">=</span> conv2_acti<span style="color:#f92672">.</span>predict(inputs)
</span></span></code></pre></div><ul>
<li>첫 번째 풀링 층에서 가로세로 크기가 절반으로 줄었고, 두 번째 합성곱 층의 필터 개수는 64개이므로 feature_maps의 크기는 배치 차원을 제외하면 (14, 14, 64)일 것</li>
</ul>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span>print(feature_maps<span style="color:#f92672">.</span>shape)
</span></span></code></pre></div><pre><code>(1, 14, 14, 64)
</code></pre>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span>fig, axs <span style="color:#f92672">=</span> plt<span style="color:#f92672">.</span>subplots(<span style="color:#ae81ff">8</span>, <span style="color:#ae81ff">8</span>, figsize<span style="color:#f92672">=</span>(<span style="color:#ae81ff">12</span>, <span style="color:#ae81ff">12</span>))
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">for</span> i <span style="color:#f92672">in</span> range(<span style="color:#ae81ff">8</span>):
</span></span><span style="display:flex;"><span>  <span style="color:#66d9ef">for</span> j <span style="color:#f92672">in</span> range(<span style="color:#ae81ff">8</span>):
</span></span><span style="display:flex;"><span>    axs[i, j]<span style="color:#f92672">.</span>imshow(feature_maps[<span style="color:#ae81ff">0</span>,:,:,i<span style="color:#f92672">*</span><span style="color:#ae81ff">8</span> <span style="color:#f92672">+</span> j])
</span></span><span style="display:flex;"><span>    axs[i, j]<span style="color:#f92672">.</span>axis(<span style="color:#e6db74">&#39;off&#39;</span>)
</span></span><span style="display:flex;"><span>plt<span style="color:#f92672">.</span>show()
</span></span></code></pre></div><p><img src="/images/self_study_ml_dl_images/chapter8_3/output_54_0.png" alt="png"></p>
<ul>
<li>
<p>두 번째 합성곱 층의 필터 크기는 (3, 3, 32)</p>
</li>
<li>
<p>두 번째 합성곱 층의 첫 번째 필터가 앞서 출력한 32개의 특성 맵과 곱해져 두 번째 합성곱 층의 첫 번째 특성 맵이 됨</p>
</li>
<li>
<p>(14, 14, 32) 특성 맵에서 어떤 부위를 감지하는지 직관적으로 이해하기가 어려움</p>
</li>
<li>
<p>이런 현상은 합성곱 층을 많이 쌓을수록 심해짐</p>
</li>
<li>
<p>합성곱 신경망의 앞부분에 있는 합성곱 층은 이미지의 시각적인 정보를 감지하고 뒤쪽에 있는 합성곱 층은 앞쪽에서 감지한 시각적인 정보를 바탕으로 추상적인 정보를 학습함</p>
</li>
</ul>
<h2 id="마무리">마무리</h2>
<h3 id="키워드로-끝내는-핵심-포인트">키워드로 끝내는 핵심 포인트</h3>
<blockquote>
<p>가중치 시각화 : 합성곱 층의 가중치를 이미지로 출력하는 것.</p>
</blockquote>
<ul>
<li>합성곱 신경망은 주로 이미지를 다루기 때문에 가중치가 시각적인 패턴을 학습하는지 알아볼 수 있음</li>
</ul>
<blockquote>
<p>특성 맵 시각화 : 합성곱 층의 활성화 출력을 이미지로 그리는 것</p>
</blockquote>
<ul>
<li>가중치 시각화와 함께 비교하여 각 필터가 이미지의 어느 부분을 활성화시키는지 확인 가능</li>
</ul>
<blockquote>
<p>함수형 API : 케라스에서 신경망 모델을 마드는 방법 중 하나</p>
</blockquote>
<ul>
<li>Model 클래스에 모델의 입려과 출력을 지정.</li>
<li>전형적으로 입력은 Input() 함수를 사용하여 정의하고 출력은 마지막 층의 출력으로 정의</li>
</ul>
<h3 id="핵심-패키지와-함수">핵심 패키지와 함수</h3>
<blockquote>
<p>TensorFlow</p>
</blockquote>
<ul>
<li>Model : 케라스 모델을 만드는 클래스
<ul>
<li>첫 번째 매개변수인 inputs에 모델의 입력 또는 입력의 리스트를 지정</li>
<li>두 번째 매개변수인 outputs에 모델의 출력 또는 출력의 리스트를 지정</li>
<li>name 매개변수에 모델의 이름을 지정 가능</li>
</ul>
</li>
</ul>
<h1 id="book--혼자-공부하는-머신러닝--딥러닝-박해선-지음-한빛미디어">Book : &lsquo;혼자 공부하는 머신러닝 + 딥러닝&rsquo;, 박해선 지음, 한빛미디어</h1>
		</div>
		<footer class="post__footer">
			
<div class="post__tags tags clearfix">
	<svg class="tags__badge icon icon-tag" width="16" height="16" viewBox="0 0 32 32"><path d="M32 19c0 1-1 2-1 2L21 31s-1 1-2 1-2-1-2-1L2 16c-1-1-1.4-2-1.4-2S0 12.5 0 11V3C0 1.5.8.8.8.8S1.5 0 3 0h8c1.5 0 3 .6 3 .6S15 1 16 2l15 15s1 1 1 2zM7 10a3 3 0 1 0 0-6 3 3 0 0 0 0 6z"/></svg>
	<ul class="tags__list">
		<li class="tags__item">
			<a class="tags__link btn" href="/tags/python/" rel="tag">Python</a>
		</li>
		<li class="tags__item">
			<a class="tags__link btn" href="/tags/book/" rel="tag">Book</a>
		</li>
	</ul>
</div>
		</footer>
	</article>
</main>

<div class="authorbox clearfix">
	<div class="authorbox__header">
		<span class="authorbox__name">About JUNG JIN WOO</span>
	</div>
</div>

<nav class="pager flex">
	<div class="pager__item pager__item--prev">
		<a class="pager__link" href="/post/dl/book/chapter8_2/" rel="prev">
			<span class="pager__subtitle">«&thinsp;Previous</span>
			<p class="pager__title">[DL][Book][혼공 머신러닝&#43;딥러닝]ch8-2 합성곱 신경망을 사용한 이미지 분류</p>
		</a>
	</div>
	<div class="pager__item pager__item--next">
		<a class="pager__link" href="/post/dl/book/chapter9_1/" rel="next">
			<span class="pager__subtitle">Next&thinsp;»</span>
			<p class="pager__title">[DL][Book][혼공 머신러닝&#43;딥러닝]ch9-1 순차 데이터와 순환 신경망</p>
		</a>
	</div>
</nav>


			</div>
			<aside class="sidebar"><div class="widget-search widget">
	<form class="widget-search__form" role="search" method="get" action="https://google.com/search">
		<label>
			<input class="widget-search__field" type="search" placeholder="SEARCH…" value="" name="q" aria-label="SEARCH…">
		</label>
		<input class="widget-search__submit" type="submit" value="Search">
		<input type="hidden" name="sitesearch" value="/" />
	</form>
</div>
<div class="widget-recent widget">
	<h4 class="widget__title">Recent Posts</h4>
	<div class="widget__content">
		<ul class="widget__list">
			<li class="widget__item"><a class="widget__link" href="/post/projects/%EB%B6%80%EB%8F%99%EC%82%B02%ED%8C%80chatbot/">[Project][Chatbot]공공 주택 정보 알림 챗봇 - 홈마트</a></li>
			<li class="widget__item"><a class="widget__link" href="/post/lang_java_script/study/condition/javascript_if_%EC%A1%B0%EA%B1%B4%EB%AC%B8/">[JavaScript] if 조건문</a></li>
			<li class="widget__item"><a class="widget__link" href="/post/lang_java_script/study/data_var/javascript_%EB%B6%88_%EC%9E%90%EB%A3%8C%ED%98%95%EC%9C%BC%EB%A1%9C_%EB%B3%80%ED%99%98/">[JavaScript] 불 자료형으로 변환</a></li>
			<li class="widget__item"><a class="widget__link" href="/post/lang_java_script/study/data_var/javascript_%EB%AC%B8%EC%9E%90%EC%97%B4_%EC%9E%90%EB%A3%8C%ED%98%95%EC%9C%BC%EB%A1%9C_%EB%B3%80%ED%99%98/">[JavaScript] 문자열 자료형으로 변환</a></li>
			<li class="widget__item"><a class="widget__link" href="/post/lang_java_script/study/data_var/javascript_%EC%88%AB%EC%9E%90-%EC%9E%90%EB%A3%8C%ED%98%95%EC%9C%BC%EB%A1%9C_%EB%B3%80%ED%99%98/">[JavaScript] 숫자 자료형으로 변환</a></li>
		</ul>
	</div>
</div>
<div class="widget-categories widget">
	<h4 class="widget__title">Categories</h4>
	<div class="widget__content">
		<ul class="widget__list">
			<li class="widget__item">
				<a class="widget__link" href="/categories/dl/">DL</a></li>
			<li class="widget__item">
				<a class="widget__link" href="/categories/javascript/">JavaScript</a></li>
			<li class="widget__item">
				<a class="widget__link" href="/categories/kaggle/">Kaggle</a></li>
			<li class="widget__item">
				<a class="widget__link" href="/categories/ml/">ML</a></li>
			<li class="widget__item">
				<a class="widget__link" href="/categories/projects/">Projects</a></li>
			<li class="widget__item">
				<a class="widget__link" href="/categories/python/">Python</a></li>
			<li class="widget__item">
				<a class="widget__link" href="/categories/setting/">Setting</a></li>
			<li class="widget__item">
				<a class="widget__link" href="/categories/sql/">SQL</a></li>
			<li class="widget__item">
				<a class="widget__link" href="/categories/statistics/">Statistics</a></li>
		</ul>
	</div>
</div>
<div class="widget-taglist widget">
	<h4 class="widget__title">Tags</h4>
	<div class="widget__content">
		<a class="widget-taglist__link widget__link btn" href="/tags/book/" title="Book">Book</a>
		<a class="widget-taglist__link widget__link btn" href="/tags/chatbot/" title="Chatbot">Chatbot</a>
		<a class="widget-taglist__link widget__link btn" href="/tags/codeup/" title="CodeUp">CodeUp</a>
		<a class="widget-taglist__link widget__link btn" href="/tags/codeuppython/" title="CodeUp(Python)">CodeUp(Python)</a>
		<a class="widget-taglist__link widget__link btn" href="/tags/coding-test/" title="Coding Test">Coding Test</a>
		<a class="widget-taglist__link widget__link btn" href="/tags/dl/" title="DL">DL</a>
		<a class="widget-taglist__link widget__link btn" href="/tags/flask/" title="Flask">Flask</a>
		<a class="widget-taglist__link widget__link btn" href="/tags/kakao/" title="kakao">kakao</a>
		<a class="widget-taglist__link widget__link btn" href="/tags/ml/" title="ML">ML</a>
		<a class="widget-taglist__link widget__link btn" href="/tags/oracle/" title="Oracle">Oracle</a>
		<a class="widget-taglist__link widget__link btn" href="/tags/pl/sql/" title="PL/SQL">PL/SQL</a>
		<a class="widget-taglist__link widget__link btn" href="/tags/python/" title="Python">Python</a>
		<a class="widget-taglist__link widget__link btn" href="/tags/spark/" title="Spark">Spark</a>
		<a class="widget-taglist__link widget__link btn" href="/tags/sql/" title="SQL">SQL</a>
	</div>
</div>
</aside>
		</div>
		<footer class="footer">
	<div class="container footer__container flex">
		
		<div class="footer__copyright">
			&copy; 2022 Black_JJW&#39;s Blog.
			<span class="footer__copyright-credits">Generated with <a href="https://gohugo.io/" rel="nofollow noopener" target="_blank">Hugo</a> and <a href="https://github.com/Vimux/Mainroad/" rel="nofollow noopener" target="_blank">Mainroad</a> theme.</span>
		</div>
	</div>
</footer>
	</div>
<script async defer src="/js/menu.js"></script>

<script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.6/MathJax.js?config=TeX-AMS-MML_HTMLorMML" async>
MathJax.Hub.Config({
    tex2jax: {
      inlineMath: [['$','$'], ['\\(','\\)']],
      displayMath: [['$$','$$']],
      processEscapes: true,
      processEnvironments: true,
      skipTags: ['script', 'noscript', 'style', 'textarea', 'pre'],
      TeX: { equationNumbers: { autoNumber: "AMS" },
           extensions: ["AMSmath.js", "AMSsymbols.js"] }
    }
    });
    MathJax.Hub.Queue(function() {
      
      
      
      var all = MathJax.Hub.getAllJax(), i;
      for(i = 0; i < all.length; i += 1) {
          all[i].SourceElement().parentNode.className += ' has-jax';
      }
    });

    MathJax.Hub.Config({
    
    TeX: { equationNumbers: { autoNumber: "AMS" } }
    });
</script>
</body>
</html>